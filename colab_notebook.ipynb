{
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 1. Install Dependencies\n",
                "!pip install chromadb transformers pillow torch"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 2. Load Model & Initialize Database\n",
                "import os\n",
                "import chromadb\n",
                "from PIL import Image\n",
                "from transformers import CLIPProcessor, CLIPModel\n",
                "import torch\n",
                "\n",
                "print(\"Loading CLIP Model... (this takes ~30 seconds)\")\n",
                "model_id = \"openai/clip-vit-base-patch32\"\n",
                "model = CLIPModel.from_pretrained(model_id)\n",
                "processor = CLIPProcessor.from_pretrained(model_id)\n",
                "\n",
                "print(\"Initializing ChromaDB...\")\n",
                "client = chromadb.Client()\n",
                "collection = client.get_or_create_collection(name=\"food_gallery\")\n",
                "\n",
                "def get_image_embedding(image_path):\n",
                "    image = Image.open(image_path)\n",
                "    inputs = processor(images=image, return_tensors=\"pt\")\n",
                "    image_features = model.get_image_features(**inputs)\n",
                "    return image_features.detach().numpy().flatten().tolist()\n",
                "\n",
                "def get_text_embedding(text):\n",
                "    inputs = processor(text=[text], return_tensors=\"pt\", padding=True)\n",
                "    text_features = model.get_text_features(**inputs)\n",
                "    return text_features.detach().numpy().flatten().tolist()"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 3. Index Images from 'images' folder\n",
                "image_folder = \"images\"\n",
                "ids = []\n",
                "embeddings = []\n",
                "metadatas = []\n",
                "\n",
                "if not os.path.exists(image_folder):\n",
                "    print(f\"WARNING: Folder '{image_folder}' does not exist. Please create it and upload images!\")\n",
                "else:\n",
                "    print(f\"Indexing images from {image_folder}...\")\n",
                "    files = [f for f in os.listdir(image_folder) if f.lower().endswith(('.jpg', '.jpeg', '.png'))]\n",
                "    \n",
                "    if not files:\n",
                "        print(\"No images found in folder! Upload some .jpg files.\")\n",
                "    \n",
                "    for filename in files:\n",
                "        path = os.path.join(image_folder, filename)\n",
                "        try:\n",
                "            vector = get_image_embedding(path)\n",
                "            ids.append(filename)\n",
                "            embeddings.append(vector)\n",
                "            metadatas.append({\"source\": filename})\n",
                "            print(f\"Indexed: {filename}\")\n",
                "        except Exception as e:\n",
                "            print(f\"Error indexing {filename}: {e}\")\n",
                "\n",
                "    if ids:\n",
                "        collection.add(embeddings=embeddings, ids=ids, metadatas=metadatas)\n",
                "        print(f\"Finished! {len(ids)} images in database.\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": [
                "# 4. Search\n",
                "from IPython.display import display\n",
                "\n",
                "query = \"healthy green food\"  # <--- CHANGE THIS TEXT TO SEARCH\n",
                "\n",
                "print(f\"Searching for: '{query}'\")\n",
                "query_vector = get_text_embedding(query)\n",
                "\n",
                "results = collection.query(\n",
                "    query_embeddings=[query_vector],\n",
                "    n_results=1\n",
                ")\n",
                "\n",
                "if results['ids']:\n",
                "    best_match = results['ids'][0][0]\n",
                "    print(f\"Best match: {best_match}\")\n",
                "    display(Image.open(os.path.join(image_folder, best_match)).resize((300, 200)))\n",
                "else:\n",
                "    print(\"No match found.\")"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.10.12"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
